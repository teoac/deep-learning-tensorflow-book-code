{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teoac/solarisTutorial/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/teoac/solarisTutorial/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/teoac/solarisTutorial/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/teoac/solarisTutorial/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/teoac/solarisTutorial/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/teoac/solarisTutorial/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/teoac/solarisTutorial/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/teoac/solarisTutorial/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/teoac/solarisTutorial/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/teoac/solarisTutorial/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/teoac/solarisTutorial/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/teoac/solarisTutorial/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0806 17:14:41.316258 140354939819776 deprecation.py:323] From <ipython-input-2-d2e182775bb2>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "W0806 17:14:41.317454 140354939819776 deprecation.py:323] From /home/teoac/solarisTutorial/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "W0806 17:14:41.318521 140354939819776 deprecation.py:323] From /home/teoac/solarisTutorial/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataOneHot/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0806 17:14:41.560288 140354939819776 deprecation.py:323] From /home/teoac/solarisTutorial/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "W0806 17:14:41.562939 140354939819776 deprecation.py:323] From /home/teoac/solarisTutorial/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "W0806 17:14:41.608931 140354939819776 deprecation.py:323] From /home/teoac/solarisTutorial/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataOneHot/train-labels-idx1-ubyte.gz\n",
      "Extracting dataOneHot/t10k-images-idx3-ubyte.gz\n",
      "Extracting dataOneHot/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# MNIST 데이터 다운로드를 합니다.\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('dataOneHot/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습을 위한 설정값들을 정의합니다.\n",
    "learning_rate = 0.001\n",
    "num_epochs = 1000 # 학습횟수\n",
    "batch_size = 256 # 배치 개수\n",
    "display_step = 5 # 손실 함수 출력 주기\n",
    "input_size = 784\n",
    "hidden1_size = 256\n",
    "hidden2_size = 256\n",
    "output_size = 10\n",
    "tolerance = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력값과 출력값을 받기 위한 플레이스홀더를 정의합니다.\n",
    "x = tf.placeholder(tf.float32, shape=[None,input_size], name='x')\n",
    "y = tf.placeholder(tf.float32, shape=[None,output_size], name='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN 모델을 정의합니다.\n",
    "def build_ANN(x):\n",
    "    W1 = tf.Variable(tf.random_normal(shape=[input_size,hidden1_size]), name='W1')\n",
    "    b1 = tf.Variable(tf.random_normal(shape=[hidden1_size]), name='b1')\n",
    "    H1_output = tf.nn.relu(tf.matmul(x,W1) + b1, name='L1')\n",
    "    W2 = tf.Variable(tf.random_normal(shape=[hidden1_size, hidden2_size]), name='W2')\n",
    "    b2 = tf.Variable(tf.random_normal(shape=[hidden2_size]), name='b2')\n",
    "    H2_output = tf.nn.relu(tf.matmul(H1_output,W2) + b2, name='L2')\n",
    "    W_output = tf.Variable(tf.random_normal(shape=[hidden2_size,output_size]), name='Wout')\n",
    "    b_output = tf.Variable(tf.random_normal(shape=[output_size]), name='bout')\n",
    "    logits = tf.matmul(H2_output, W_output) + b_output\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN 모델을 선언합니다.\n",
    "predicted_value = build_ANN(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실 함수와 옵티마이저를 정의합니다.\n",
    "loss_function = tf.nn.softmax_cross_entropy_with_logits_v2(logits=predicted_value, labels=y)\n",
    "loss = tf.reduce_mean(loss_function)\n",
    "train_step = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Loss:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 텐서보드를 위한 요약 정보(scalar)를 정의합니다.\n",
    "tf.summary.scalar(\"Loss\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 308.849482\n",
      "Epoch: 5, Loss: 25.309010\n",
      "Epoch: 10, Loss: 9.637833\n",
      "Epoch: 15, Loss: 3.964542\n",
      "Epoch: 20, Loss: 1.410634\n",
      "Epoch: 25, Loss: 0.527363\n",
      "Epoch: 30, Loss: 0.253234\n",
      "Epoch: 35, Loss: 0.142652\n",
      "Epoch: 40, Loss: 0.117087\n",
      "Epoch: 45, Loss: 0.146814\n",
      "Epoch: 50, Loss: 0.114887\n",
      "Epoch: 55, Loss: 0.105624\n",
      "Epoch: 60, Loss: 0.121314\n",
      "Epoch: 62, Loss: 0.096998\n",
      "Accuracy: 0.957300\n"
     ]
    }
   ],
   "source": [
    "# 세션을 열고 그래프를 실행합니다.\n",
    "with tf.Session() as sess:\n",
    "    # 변수들에 초기값을 할당합니다.\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # 텐서보드 요약정보들을 하나로 합칩니다.\n",
    "    merged = tf.summary.merge_all()\n",
    "    # 텐서보드 summary 정보들을 저장할 폴더 경로를 설정합니다.\n",
    "    tensorboard_writer = tf.summary.FileWriter('./tensorboard_log', sess.graph)\n",
    "    # 지정된 횟수만큼 최적화를 수행합니다.\n",
    "    epoch = 0\n",
    "    average_loss_prev = 0.0\n",
    "    while epoch < num_epochs:\n",
    "        average_loss = 0.0\n",
    "        #전체 배치를 불러옵니다.\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        # 모든 배치들에 대해서 최적화를 수행합니다.\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            # 옵티마이저를 실행해서 파라미터들을 업데이트 합니다.\n",
    "            _, current_loss = sess.run([train_step, loss], feed_dict={x:batch_x, y:batch_y})\n",
    "            # 평균 손실을 측정합니다.\n",
    "            average_loss += current_loss / total_batch\n",
    "        # 텐서보드에 기록합니다.\n",
    "        summary = sess.run(merged, feed_dict={x: batch_x, y: batch_y})\n",
    "        tensorboard_writer.add_summary(summary, epoch)\n",
    "        # 지정된 epoch마다 학습결과를 출력합니다.\n",
    "        if epoch%display_step == display_step-1 or epoch == 0:\n",
    "            print('Epoch: %d, Loss: %f' %((epoch+1), average_loss))\n",
    "        #수렴했으면 학습종료\n",
    "        if abs(average_loss_prev - average_loss) < tolerance:\n",
    "            print('Epoch: %d, Loss: %f' %((epoch+1), average_loss))\n",
    "            break\n",
    "        average_loss_prev = average_loss\n",
    "        epoch += 1\n",
    "        \n",
    "    # 테스트 데이터를 이용해서 학습된 모델이 얼마나 정확한지 정확도를 출력합니다.\n",
    "    correct_prediction = tf.equal(tf.argmax(predicted_value,1), tf.argmax(y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))\n",
    "    print('Accuracy: %f' %(accuracy.eval(feed_dict={x:mnist.test.images, y:mnist.test.labels})))\n",
    "    \n",
    "    # 세션을 종료합니다.\n",
    "    sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
